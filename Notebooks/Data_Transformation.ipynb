{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to PostgreSQL successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['truck_schedule_table',\n",
       " 'routes_table',\n",
       " 'routes_weather',\n",
       " 'trucks_table',\n",
       " 'traffic_table',\n",
       " 'drivers_table',\n",
       " 'city_weather']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, inspect\n",
    "from utils.database_utils import *\n",
    "from utils.config_utils import *\n",
    "from constants import *\n",
    "\n",
    "db_config = get_db_config(read_config(CONFIG_FILE_PATH))\n",
    "# Create SQLAlchemy engine\n",
    "engine = connect(db_config)\n",
    "\n",
    "# Connect and Inspect\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Get table names\n",
    "table_names = inspector.get_table_names()\n",
    "table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1022104\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "2024-10-18 14:56:15,638 WARNING: DeprecationWarning: ssl.PROTOCOL_TLS is deprecated\n",
      "\n",
      "Finished: Reading data from Hopsworks, using Hive (2.42s) \n",
      "{'final_merge_fg':        unique_id  truck_id    route_id      departure_date  \\\n",
      "0           9778  22007337  R-b69ad412 2019-01-16 07:00:00   \n",
      "1           1566  12052665  R-9e7d29c6 2019-01-07 07:00:00   \n",
      "2           7277  57473533  R-ef8dd68d 2019-02-03 07:00:00   \n",
      "3           9026  99047862  R-58474583 2019-02-12 07:00:00   \n",
      "4           2016  19445339  R-d52fc715 2019-01-10 07:00:00   \n",
      "...          ...       ...         ...                 ...   \n",
      "10516       4237  43346401  R-089c9405 2019-01-19 07:00:00   \n",
      "10517       3517  22748353  R-8656be91 2019-01-16 07:00:00   \n",
      "10518      10526  29066789  R-0810e90f 2019-02-10 07:00:00   \n",
      "10519       1187  81492294  R-bfb1ad59 2019-01-04 07:00:00   \n",
      "10520      10275  26749209  R-2b5aba88 2019-01-31 07:00:00   \n",
      "\n",
      "        estimated_arrival  delay  route_avg_temp  route_avg_wind_speed  \\\n",
      "0     2019-01-17 11:14:24      1       45.333333             14.000000   \n",
      "1     2019-01-07 14:26:24      0       43.333333             10.000000   \n",
      "2     2019-02-04 05:19:12      1       46.200000              4.600000   \n",
      "3     2019-02-12 14:32:24      0       62.333333              7.000000   \n",
      "4     2019-01-10 08:22:48      0       73.000000              4.500000   \n",
      "...                   ...    ...             ...                   ...   \n",
      "10516 2019-01-19 16:07:48      0       61.333333              9.333333   \n",
      "10517 2019-01-16 16:33:36      1       68.000000              4.666667   \n",
      "10518 2019-02-11 13:26:24      1       69.166667              9.000000   \n",
      "10519 2019-01-04 13:36:00      0       79.000000              4.666667   \n",
      "10520 2019-02-01 13:02:24      1       66.428571              6.714286   \n",
      "\n",
      "       route_avg_precip  route_avg_humidity  ...              name  gender  \\\n",
      "0                   0.0           92.000000  ...      Ricardo Pena    male   \n",
      "1                   0.0           65.666667  ...    Greg Gallagher    male   \n",
      "2                   0.0           57.600000  ...    Dr. Chad Garza    male   \n",
      "3                   0.0           68.000000  ...   Matthew Allison    male   \n",
      "4                   0.0           93.500000  ...  Dr. Gregory Lutz    male   \n",
      "...                 ...                 ...  ...               ...     ...   \n",
      "10516               0.0           78.000000  ...      Edward Myers    male   \n",
      "10517               0.0           77.666667  ...    Manuel Jimenez    male   \n",
      "10518               0.0           50.500000  ...         Adam Holt    male   \n",
      "10519               0.0           67.333333  ...          Gary Kim    male   \n",
      "10520               0.0           76.714286  ...        John Bates    male   \n",
      "\n",
      "        age experience driving_style ratings  vehicle_no  average_speed_mph  \\\n",
      "0      50.0        9.0  conservative     7.0  22007337.0              44.91   \n",
      "1      40.0        2.0  conservative     2.0  12052665.0              43.79   \n",
      "2      40.0        5.0     proactive     3.0  57473533.0              64.71   \n",
      "3      59.0       18.0  conservative     6.0  99047862.0              44.91   \n",
      "4      45.0        1.0  conservative     8.0  19445339.0              48.44   \n",
      "...     ...        ...           ...     ...         ...                ...   \n",
      "10516  42.0        7.0  conservative     7.0  43346401.0              49.63   \n",
      "10517  42.0        8.0  conservative     3.0  22748353.0              29.32   \n",
      "10518  56.0       17.0  conservative     9.0  29066789.0              48.78   \n",
      "10519  56.0       24.0     proactive     8.0  81492294.0              64.75   \n",
      "10520  54.0       18.0  conservative     6.0  26749209.0              39.12   \n",
      "\n",
      "       is_midnight  event_time  \n",
      "0                1  2024-10-09  \n",
      "1                0  2024-10-09  \n",
      "2                1  2024-10-09  \n",
      "3                0  2024-10-09  \n",
      "4                0  2024-10-09  \n",
      "...            ...         ...  \n",
      "10516            0  2024-10-09  \n",
      "10517            0  2024-10-09  \n",
      "10518            1  2024-10-09  \n",
      "10519            0  2024-10-09  \n",
      "10520            1  2024-10-09  \n",
      "\n",
      "[10521 rows x 50 columns]}\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "\n",
    "project = hopsworks.login(api_key_value = 'HIW4D6r4iHGmgSqT.W5LdkqjulcZ85kFXhePJdfJb2sxxZigzNOtweKlAXTLiou7QVkWPBzc9gfRXMjYC')\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "feature_groups = ['final_merge_fg']\n",
    "\n",
    "feature_dataframes = {}\n",
    "\n",
    "# Loop through each feature group and fetch the data\n",
    "for fg_name in feature_groups:\n",
    "    # Get the feature group object\n",
    "    fg = fs.get_feature_group(fg_name, version=1)  # Ensure you use the correct version\n",
    "    \n",
    "    # Fetch the data as a Pandas DataFrame\n",
    "    query = fg.select_all()\n",
    "    df=query.read(read_options={\"use_hive\": True})\n",
    "    # df = fg.read(read_options={\"use_hive\": True})\n",
    "    \n",
    "    # Store in dictionary\n",
    "    feature_dataframes[fg_name] = df\n",
    "\n",
    "# Now you have a dictionary of DataFrames, where the key is the feature group name\n",
    "print(feature_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in feature_dataframes.items():\n",
    "    if 'event_time' in df.columns:\n",
    "        df.drop(columns=['event_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge = feature_dataframes['final_merge_fg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>truck_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>estimated_arrival</th>\n",
       "      <th>delay</th>\n",
       "      <th>route_avg_temp</th>\n",
       "      <th>route_avg_wind_speed</th>\n",
       "      <th>route_avg_precip</th>\n",
       "      <th>route_avg_humidity</th>\n",
       "      <th>...</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "      <th>driving_style</th>\n",
       "      <th>ratings</th>\n",
       "      <th>vehicle_no</th>\n",
       "      <th>average_speed_mph</th>\n",
       "      <th>is_midnight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9778</td>\n",
       "      <td>22007337</td>\n",
       "      <td>R-b69ad412</td>\n",
       "      <td>2019-01-16 07:00:00</td>\n",
       "      <td>2019-01-17 11:14:24</td>\n",
       "      <td>1</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1aabc91a-c</td>\n",
       "      <td>Ricardo Pena</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>conservative</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22007337.0</td>\n",
       "      <td>44.91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1566</td>\n",
       "      <td>12052665</td>\n",
       "      <td>R-9e7d29c6</td>\n",
       "      <td>2019-01-07 07:00:00</td>\n",
       "      <td>2019-01-07 14:26:24</td>\n",
       "      <td>0</td>\n",
       "      <td>43.333333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>45b11b01-6</td>\n",
       "      <td>Greg Gallagher</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>conservative</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12052665.0</td>\n",
       "      <td>43.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7277</td>\n",
       "      <td>57473533</td>\n",
       "      <td>R-ef8dd68d</td>\n",
       "      <td>2019-02-03 07:00:00</td>\n",
       "      <td>2019-02-04 05:19:12</td>\n",
       "      <td>1</td>\n",
       "      <td>46.200000</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>fde76a0f-7</td>\n",
       "      <td>Dr. Chad Garza</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>proactive</td>\n",
       "      <td>3.0</td>\n",
       "      <td>57473533.0</td>\n",
       "      <td>64.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9026</td>\n",
       "      <td>99047862</td>\n",
       "      <td>R-58474583</td>\n",
       "      <td>2019-02-12 07:00:00</td>\n",
       "      <td>2019-02-12 14:32:24</td>\n",
       "      <td>0</td>\n",
       "      <td>62.333333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>b722825b-3</td>\n",
       "      <td>Matthew Allison</td>\n",
       "      <td>male</td>\n",
       "      <td>59.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>conservative</td>\n",
       "      <td>6.0</td>\n",
       "      <td>99047862.0</td>\n",
       "      <td>44.91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>19445339</td>\n",
       "      <td>R-d52fc715</td>\n",
       "      <td>2019-01-10 07:00:00</td>\n",
       "      <td>2019-01-10 08:22:48</td>\n",
       "      <td>0</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>95f5db58-1</td>\n",
       "      <td>Dr. Gregory Lutz</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>conservative</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19445339.0</td>\n",
       "      <td>48.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id  truck_id    route_id      departure_date   estimated_arrival  \\\n",
       "0       9778  22007337  R-b69ad412 2019-01-16 07:00:00 2019-01-17 11:14:24   \n",
       "1       1566  12052665  R-9e7d29c6 2019-01-07 07:00:00 2019-01-07 14:26:24   \n",
       "2       7277  57473533  R-ef8dd68d 2019-02-03 07:00:00 2019-02-04 05:19:12   \n",
       "3       9026  99047862  R-58474583 2019-02-12 07:00:00 2019-02-12 14:32:24   \n",
       "4       2016  19445339  R-d52fc715 2019-01-10 07:00:00 2019-01-10 08:22:48   \n",
       "\n",
       "   delay  route_avg_temp  route_avg_wind_speed  route_avg_precip  \\\n",
       "0      1       45.333333                  14.0               0.0   \n",
       "1      0       43.333333                  10.0               0.0   \n",
       "2      1       46.200000                   4.6               0.0   \n",
       "3      0       62.333333                   7.0               0.0   \n",
       "4      0       73.000000                   4.5               0.0   \n",
       "\n",
       "   route_avg_humidity  ...   driver_id              name gender   age  \\\n",
       "0           92.000000  ...  1aabc91a-c      Ricardo Pena   male  50.0   \n",
       "1           65.666667  ...  45b11b01-6    Greg Gallagher   male  40.0   \n",
       "2           57.600000  ...  fde76a0f-7    Dr. Chad Garza   male  40.0   \n",
       "3           68.000000  ...  b722825b-3   Matthew Allison   male  59.0   \n",
       "4           93.500000  ...  95f5db58-1  Dr. Gregory Lutz   male  45.0   \n",
       "\n",
       "  experience driving_style ratings  vehicle_no  average_speed_mph  is_midnight  \n",
       "0        9.0  conservative     7.0  22007337.0              44.91            1  \n",
       "1        2.0  conservative     2.0  12052665.0              43.79            0  \n",
       "2        5.0     proactive     3.0  57473533.0              64.71            1  \n",
       "3       18.0  conservative     6.0  99047862.0              44.91            0  \n",
       "4        1.0  conservative     8.0  19445339.0              48.44            0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts_cols=['route_avg_temp', 'route_avg_wind_speed',\n",
    "              'route_avg_precip', 'route_avg_humidity', 'route_avg_visibility',\n",
    "              'route_avg_pressure', 'distance', 'average_hours',\n",
    "              'origin_temp', 'origin_wind_speed', 'origin_precip', 'origin_humidity',\n",
    "              'origin_visibility', 'origin_pressure',\n",
    "              'destination_temp','destination_wind_speed','destination_precip',\n",
    "              'destination_humidity', 'destination_visibility','destination_pressure',\n",
    "               'avg_no_of_vehicles', 'truck_age','load_capacity_pounds', 'mileage_mpg',\n",
    "               'age', 'experience','average_speed_mph']\n",
    "       \n",
    "       \n",
    "cat_cols=['route_description',\n",
    "        'origin_description', 'destination_description',\n",
    "        'accident', 'fuel_type',\n",
    "        'gender', 'driving_style', 'ratings','is_midnight']\n",
    "\n",
    "\n",
    "target=['delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-01-01 07:04:48'), Timestamp('2019-02-14 10:01:48'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merge['estimated_arrival'].min(), final_merge['estimated_arrival'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = final_merge[final_merge['estimated_arrival'] <= pd.to_datetime('2019-01-30')]\n",
    "\n",
    "validation_df = final_merge[(final_merge['estimated_arrival'] > pd.to_datetime('2019-01-30')) &\n",
    "\n",
    "                            (final_merge['estimated_arrival'] <= pd.to_datetime('2019-02-07'))]\n",
    "\n",
    "test_df = final_merge[final_merge['estimated_arrival'] > pd.to_datetime('2019-02-07')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df[cts_cols+cat_cols]\n",
    "y_train=train_df['delay']\n",
    "\n",
    "X_valid = validation_df[cts_cols + cat_cols]\n",
    "y_valid = validation_df['delay']\n",
    "\n",
    "X_test=test_df[cts_cols+cat_cols]\n",
    "y_test=test_df['delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_avg_temp</th>\n",
       "      <th>route_avg_wind_speed</th>\n",
       "      <th>route_avg_precip</th>\n",
       "      <th>route_avg_humidity</th>\n",
       "      <th>route_avg_visibility</th>\n",
       "      <th>route_avg_pressure</th>\n",
       "      <th>distance</th>\n",
       "      <th>average_hours</th>\n",
       "      <th>origin_temp</th>\n",
       "      <th>origin_wind_speed</th>\n",
       "      <th>...</th>\n",
       "      <th>average_speed_mph</th>\n",
       "      <th>route_description</th>\n",
       "      <th>origin_description</th>\n",
       "      <th>destination_description</th>\n",
       "      <th>accident</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>gender</th>\n",
       "      <th>driving_style</th>\n",
       "      <th>ratings</th>\n",
       "      <th>is_midnight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.333333</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1019.666667</td>\n",
       "      <td>1412.20</td>\n",
       "      <td>28.24</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.91</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>1</td>\n",
       "      <td>diesel</td>\n",
       "      <td>male</td>\n",
       "      <td>conservative</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.333333</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.666667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1023.000000</td>\n",
       "      <td>371.86</td>\n",
       "      <td>7.44</td>\n",
       "      <td>57.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.79</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Patchy light drizzle</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>0</td>\n",
       "      <td>gas</td>\n",
       "      <td>male</td>\n",
       "      <td>conservative</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1016.500000</td>\n",
       "      <td>69.24</td>\n",
       "      <td>1.38</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.44</td>\n",
       "      <td>Mist</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>0</td>\n",
       "      <td>gas</td>\n",
       "      <td>male</td>\n",
       "      <td>conservative</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1020.250000</td>\n",
       "      <td>559.02</td>\n",
       "      <td>11.18</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.61</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Clear</td>\n",
       "      <td>1</td>\n",
       "      <td>gas</td>\n",
       "      <td>male</td>\n",
       "      <td>conservative</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79.142857</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>67.857143</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>1015.000000</td>\n",
       "      <td>1619.87</td>\n",
       "      <td>32.40</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.13</td>\n",
       "      <td>Moderate or heavy rain shower</td>\n",
       "      <td>Patchy light snow</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>1</td>\n",
       "      <td>diesel</td>\n",
       "      <td>male</td>\n",
       "      <td>proactive</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10513</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.250000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>1007.750000</td>\n",
       "      <td>677.39</td>\n",
       "      <td>13.55</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.70</td>\n",
       "      <td>Light rain</td>\n",
       "      <td>Blizzard</td>\n",
       "      <td>Heavy snow</td>\n",
       "      <td>1</td>\n",
       "      <td>gas</td>\n",
       "      <td>male</td>\n",
       "      <td>proactive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10515</th>\n",
       "      <td>51.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1020.333333</td>\n",
       "      <td>454.49</td>\n",
       "      <td>9.09</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.91</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>1</td>\n",
       "      <td>gas</td>\n",
       "      <td>male</td>\n",
       "      <td>proactive</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10516</th>\n",
       "      <td>61.333333</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1021.333333</td>\n",
       "      <td>456.29</td>\n",
       "      <td>9.13</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.63</td>\n",
       "      <td>Light rain shower</td>\n",
       "      <td>Blowing snow</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>1</td>\n",
       "      <td>diesel</td>\n",
       "      <td>male</td>\n",
       "      <td>conservative</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10517</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.666667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>478.08</td>\n",
       "      <td>9.56</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.32</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>1</td>\n",
       "      <td>diesel</td>\n",
       "      <td>male</td>\n",
       "      <td>conservative</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10519</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1013.666667</td>\n",
       "      <td>330.15</td>\n",
       "      <td>6.60</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.75</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>1</td>\n",
       "      <td>diesel</td>\n",
       "      <td>male</td>\n",
       "      <td>proactive</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7326 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       route_avg_temp  route_avg_wind_speed  route_avg_precip  \\\n",
       "0           45.333333             14.000000          0.000000   \n",
       "1           43.333333             10.000000          0.000000   \n",
       "4           73.000000              4.500000          0.000000   \n",
       "5           64.000000              7.500000          0.000000   \n",
       "6           79.142857             11.428571          0.042857   \n",
       "...               ...                   ...               ...   \n",
       "10513       65.000000              6.250000          0.000000   \n",
       "10515       51.666667              5.333333          0.000000   \n",
       "10516       61.333333              9.333333          0.000000   \n",
       "10517       68.000000              4.666667          0.000000   \n",
       "10519       79.000000              4.666667          0.000000   \n",
       "\n",
       "       route_avg_humidity  route_avg_visibility  route_avg_pressure  distance  \\\n",
       "0               92.000000              6.000000         1019.666667   1412.20   \n",
       "1               65.666667              6.000000         1023.000000    371.86   \n",
       "4               93.500000              3.500000         1016.500000     69.24   \n",
       "5               58.000000              6.000000         1020.250000    559.02   \n",
       "6               67.857143              4.857143         1015.000000   1619.87   \n",
       "...                   ...                   ...                 ...       ...   \n",
       "10513           67.250000              5.750000         1007.750000    677.39   \n",
       "10515           88.333333              6.000000         1020.333333    454.49   \n",
       "10516           78.000000              6.000000         1021.333333    456.29   \n",
       "10517           77.666667              6.000000         1012.000000    478.08   \n",
       "10519           67.333333              6.000000         1013.666667    330.15   \n",
       "\n",
       "       average_hours  origin_temp  origin_wind_speed  ...  average_speed_mph  \\\n",
       "0              28.24         32.0                6.0  ...              44.91   \n",
       "1               7.44         57.0               11.0  ...              43.79   \n",
       "4               1.38         23.0                4.0  ...              48.44   \n",
       "5              11.18         21.0                8.0  ...              42.61   \n",
       "6              32.40         14.0               11.0  ...              60.13   \n",
       "...              ...          ...                ...  ...                ...   \n",
       "10513          13.55         21.0               14.0  ...              58.70   \n",
       "10515           9.09         14.0                5.0  ...              59.91   \n",
       "10516           9.13         27.0               19.0  ...              49.63   \n",
       "10517           9.56         37.0                2.0  ...              29.32   \n",
       "10519           6.60         34.0                7.0  ...              64.75   \n",
       "\n",
       "                   route_description    origin_description  \\\n",
       "0                           Overcast                 Sunny   \n",
       "1                              Sunny  Patchy light drizzle   \n",
       "4                               Mist         Partly cloudy   \n",
       "5                              Clear                 Sunny   \n",
       "6      Moderate or heavy rain shower     Patchy light snow   \n",
       "...                              ...                   ...   \n",
       "10513                     Light rain              Blizzard   \n",
       "10515                  Partly cloudy                 Sunny   \n",
       "10516              Light rain shower          Blowing snow   \n",
       "10517                  Partly cloudy                 Sunny   \n",
       "10519                  Partly cloudy                 Sunny   \n",
       "\n",
       "       destination_description  accident  fuel_type  gender  driving_style  \\\n",
       "0                Partly cloudy         1     diesel    male   conservative   \n",
       "1                       Cloudy         0        gas    male   conservative   \n",
       "4                        Sunny         0        gas    male   conservative   \n",
       "5                        Clear         1        gas    male   conservative   \n",
       "6                        Sunny         1     diesel    male      proactive   \n",
       "...                        ...       ...        ...     ...            ...   \n",
       "10513               Heavy snow         1        gas    male      proactive   \n",
       "10515                    Sunny         1        gas    male      proactive   \n",
       "10516            Partly cloudy         1     diesel    male   conservative   \n",
       "10517                 Overcast         1     diesel    male   conservative   \n",
       "10519                    Sunny         1     diesel    male      proactive   \n",
       "\n",
       "       ratings  is_midnight  \n",
       "0          7.0            1  \n",
       "1          2.0            0  \n",
       "4          8.0            0  \n",
       "5          2.0            0  \n",
       "6          4.0            1  \n",
       "...        ...          ...  \n",
       "10513      5.0            0  \n",
       "10515      7.0            0  \n",
       "10516      7.0            0  \n",
       "10517      3.0            0  \n",
       "10519      8.0            0  \n",
       "\n",
       "[7326 rows x 36 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder_columns = ['route_description', 'origin_description', 'destination_description', 'fuel_type', 'gender', 'driving_style']\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False,handle_unknown='ignore')\n",
    "encoder.fit(X_train[encoder_columns])\n",
    "encoded_features = list(encoder.get_feature_names_out(encoder_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 15:04:09,334 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 15:04:09,339 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,341 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,342 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,345 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,347 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,349 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,351 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,353 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,354 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,355 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,357 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,384 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,389 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,392 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,396 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,400 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,403 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,407 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,411 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,415 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,418 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,419 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,421 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,424 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,426 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,428 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,430 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,432 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,434 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,452 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,453 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,455 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,457 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,459 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,461 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,462 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,464 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,465 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,467 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,468 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,470 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,481 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,482 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,483 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,485 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,487 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,488 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,489 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,491 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,492 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,494 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,495 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,496 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,498 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,499 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,500 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,502 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,503 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,505 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,512 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,514 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,515 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,516 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,517 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,517 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,519 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,520 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,521 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,522 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,523 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,526 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2024-10-18 15:04:09,537 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,538 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,540 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,541 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,543 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,545 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,547 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,549 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,551 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,552 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,555 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,556 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,558 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,559 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,561 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,563 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,564 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "2024-10-18 15:04:09,565 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train[encoded_features] = encoder.transform(X_train[encoder_columns])\n",
    "\n",
    "X_valid[encoded_features] = encoder.transform(X_valid[encoder_columns])\n",
    "\n",
    "X_test[encoded_features] = encoder.transform(X_test[encoder_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_avg_temp</th>\n",
       "      <th>route_avg_wind_speed</th>\n",
       "      <th>route_avg_precip</th>\n",
       "      <th>route_avg_humidity</th>\n",
       "      <th>route_avg_visibility</th>\n",
       "      <th>route_avg_pressure</th>\n",
       "      <th>distance</th>\n",
       "      <th>average_hours</th>\n",
       "      <th>origin_temp</th>\n",
       "      <th>origin_wind_speed</th>\n",
       "      <th>...</th>\n",
       "      <th>destination_description_Patchy rain possible</th>\n",
       "      <th>destination_description_Patchy snow possible</th>\n",
       "      <th>destination_description_Sunny</th>\n",
       "      <th>destination_description_Torrential rain shower</th>\n",
       "      <th>fuel_type_diesel</th>\n",
       "      <th>fuel_type_gas</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>driving_style_conservative</th>\n",
       "      <th>driving_style_proactive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.333333</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1019.666667</td>\n",
       "      <td>1412.20</td>\n",
       "      <td>28.24</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.333333</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.666667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1023.000000</td>\n",
       "      <td>371.86</td>\n",
       "      <td>7.44</td>\n",
       "      <td>57.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1016.500000</td>\n",
       "      <td>69.24</td>\n",
       "      <td>1.38</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1020.250000</td>\n",
       "      <td>559.02</td>\n",
       "      <td>11.18</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79.142857</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>67.857143</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>1015.000000</td>\n",
       "      <td>1619.87</td>\n",
       "      <td>32.40</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10513</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.250000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>1007.750000</td>\n",
       "      <td>677.39</td>\n",
       "      <td>13.55</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10515</th>\n",
       "      <td>51.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1020.333333</td>\n",
       "      <td>454.49</td>\n",
       "      <td>9.09</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10516</th>\n",
       "      <td>61.333333</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1021.333333</td>\n",
       "      <td>456.29</td>\n",
       "      <td>9.13</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10517</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.666667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>478.08</td>\n",
       "      <td>9.56</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10519</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1013.666667</td>\n",
       "      <td>330.15</td>\n",
       "      <td>6.60</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7326 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       route_avg_temp  route_avg_wind_speed  route_avg_precip  \\\n",
       "0           45.333333             14.000000          0.000000   \n",
       "1           43.333333             10.000000          0.000000   \n",
       "4           73.000000              4.500000          0.000000   \n",
       "5           64.000000              7.500000          0.000000   \n",
       "6           79.142857             11.428571          0.042857   \n",
       "...               ...                   ...               ...   \n",
       "10513       65.000000              6.250000          0.000000   \n",
       "10515       51.666667              5.333333          0.000000   \n",
       "10516       61.333333              9.333333          0.000000   \n",
       "10517       68.000000              4.666667          0.000000   \n",
       "10519       79.000000              4.666667          0.000000   \n",
       "\n",
       "       route_avg_humidity  route_avg_visibility  route_avg_pressure  distance  \\\n",
       "0               92.000000              6.000000         1019.666667   1412.20   \n",
       "1               65.666667              6.000000         1023.000000    371.86   \n",
       "4               93.500000              3.500000         1016.500000     69.24   \n",
       "5               58.000000              6.000000         1020.250000    559.02   \n",
       "6               67.857143              4.857143         1015.000000   1619.87   \n",
       "...                   ...                   ...                 ...       ...   \n",
       "10513           67.250000              5.750000         1007.750000    677.39   \n",
       "10515           88.333333              6.000000         1020.333333    454.49   \n",
       "10516           78.000000              6.000000         1021.333333    456.29   \n",
       "10517           77.666667              6.000000         1012.000000    478.08   \n",
       "10519           67.333333              6.000000         1013.666667    330.15   \n",
       "\n",
       "       average_hours  origin_temp  origin_wind_speed  ...  \\\n",
       "0              28.24         32.0                6.0  ...   \n",
       "1               7.44         57.0               11.0  ...   \n",
       "4               1.38         23.0                4.0  ...   \n",
       "5              11.18         21.0                8.0  ...   \n",
       "6              32.40         14.0               11.0  ...   \n",
       "...              ...          ...                ...  ...   \n",
       "10513          13.55         21.0               14.0  ...   \n",
       "10515           9.09         14.0                5.0  ...   \n",
       "10516           9.13         27.0               19.0  ...   \n",
       "10517           9.56         37.0                2.0  ...   \n",
       "10519           6.60         34.0                7.0  ...   \n",
       "\n",
       "       destination_description_Patchy rain possible  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "4                                               0.0   \n",
       "5                                               0.0   \n",
       "6                                               0.0   \n",
       "...                                             ...   \n",
       "10513                                           0.0   \n",
       "10515                                           0.0   \n",
       "10516                                           0.0   \n",
       "10517                                           0.0   \n",
       "10519                                           0.0   \n",
       "\n",
       "       destination_description_Patchy snow possible  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "4                                               0.0   \n",
       "5                                               0.0   \n",
       "6                                               0.0   \n",
       "...                                             ...   \n",
       "10513                                           0.0   \n",
       "10515                                           0.0   \n",
       "10516                                           0.0   \n",
       "10517                                           0.0   \n",
       "10519                                           0.0   \n",
       "\n",
       "       destination_description_Sunny  \\\n",
       "0                                0.0   \n",
       "1                                0.0   \n",
       "4                                1.0   \n",
       "5                                0.0   \n",
       "6                                1.0   \n",
       "...                              ...   \n",
       "10513                            0.0   \n",
       "10515                            1.0   \n",
       "10516                            0.0   \n",
       "10517                            0.0   \n",
       "10519                            1.0   \n",
       "\n",
       "       destination_description_Torrential rain shower  fuel_type_diesel  \\\n",
       "0                                                 0.0               1.0   \n",
       "1                                                 0.0               0.0   \n",
       "4                                                 0.0               0.0   \n",
       "5                                                 0.0               0.0   \n",
       "6                                                 0.0               1.0   \n",
       "...                                               ...               ...   \n",
       "10513                                             0.0               0.0   \n",
       "10515                                             0.0               0.0   \n",
       "10516                                             0.0               1.0   \n",
       "10517                                             0.0               1.0   \n",
       "10519                                             0.0               1.0   \n",
       "\n",
       "       fuel_type_gas  gender_female  gender_male  driving_style_conservative  \\\n",
       "0                0.0            0.0          1.0                         1.0   \n",
       "1                1.0            0.0          1.0                         1.0   \n",
       "4                1.0            0.0          1.0                         1.0   \n",
       "5                1.0            0.0          1.0                         1.0   \n",
       "6                0.0            0.0          1.0                         0.0   \n",
       "...              ...            ...          ...                         ...   \n",
       "10513            1.0            0.0          1.0                         0.0   \n",
       "10515            1.0            0.0          1.0                         0.0   \n",
       "10516            0.0            0.0          1.0                         1.0   \n",
       "10517            0.0            0.0          1.0                         1.0   \n",
       "10519            0.0            0.0          1.0                         0.0   \n",
       "\n",
       "       driving_style_proactive  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "4                          0.0  \n",
       "5                          0.0  \n",
       "6                          1.0  \n",
       "...                        ...  \n",
       "10513                      1.0  \n",
       "10515                      1.0  \n",
       "10516                      0.0  \n",
       "10517                      0.0  \n",
       "10519                      1.0  \n",
       "\n",
       "[7326 rows x 151 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LAbel encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "laben = LabelEncoder()\n",
    "label_encoder_columns = ['accident', 'ratings','is_midnight']\n",
    "for col in label_encoder_columns:\n",
    "    X_train[col] = laben.fit_transform(X_train[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(encoder_columns, axis=1)\n",
    "\n",
    "X_valid = X_valid.drop(encoder_columns, axis=1)\n",
    "\n",
    "X_test = X_test.drop(encoder_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_avg_temp</th>\n",
       "      <th>route_avg_wind_speed</th>\n",
       "      <th>route_avg_precip</th>\n",
       "      <th>route_avg_humidity</th>\n",
       "      <th>route_avg_visibility</th>\n",
       "      <th>route_avg_pressure</th>\n",
       "      <th>distance</th>\n",
       "      <th>average_hours</th>\n",
       "      <th>origin_temp</th>\n",
       "      <th>origin_wind_speed</th>\n",
       "      <th>...</th>\n",
       "      <th>destination_description_Patchy rain possible</th>\n",
       "      <th>destination_description_Patchy snow possible</th>\n",
       "      <th>destination_description_Sunny</th>\n",
       "      <th>destination_description_Torrential rain shower</th>\n",
       "      <th>fuel_type_diesel</th>\n",
       "      <th>fuel_type_gas</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>driving_style_conservative</th>\n",
       "      <th>driving_style_proactive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.333333</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1019.666667</td>\n",
       "      <td>1412.20</td>\n",
       "      <td>28.24</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.333333</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.666667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1023.000000</td>\n",
       "      <td>371.86</td>\n",
       "      <td>7.44</td>\n",
       "      <td>57.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1016.500000</td>\n",
       "      <td>69.24</td>\n",
       "      <td>1.38</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1020.250000</td>\n",
       "      <td>559.02</td>\n",
       "      <td>11.18</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79.142857</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>67.857143</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>1015.000000</td>\n",
       "      <td>1619.87</td>\n",
       "      <td>32.40</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10513</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.250000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>1007.750000</td>\n",
       "      <td>677.39</td>\n",
       "      <td>13.55</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10515</th>\n",
       "      <td>51.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1020.333333</td>\n",
       "      <td>454.49</td>\n",
       "      <td>9.09</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10516</th>\n",
       "      <td>61.333333</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1021.333333</td>\n",
       "      <td>456.29</td>\n",
       "      <td>9.13</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10517</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.666667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>478.08</td>\n",
       "      <td>9.56</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10519</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1013.666667</td>\n",
       "      <td>330.15</td>\n",
       "      <td>6.60</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7326 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       route_avg_temp  route_avg_wind_speed  route_avg_precip  \\\n",
       "0           45.333333             14.000000          0.000000   \n",
       "1           43.333333             10.000000          0.000000   \n",
       "4           73.000000              4.500000          0.000000   \n",
       "5           64.000000              7.500000          0.000000   \n",
       "6           79.142857             11.428571          0.042857   \n",
       "...               ...                   ...               ...   \n",
       "10513       65.000000              6.250000          0.000000   \n",
       "10515       51.666667              5.333333          0.000000   \n",
       "10516       61.333333              9.333333          0.000000   \n",
       "10517       68.000000              4.666667          0.000000   \n",
       "10519       79.000000              4.666667          0.000000   \n",
       "\n",
       "       route_avg_humidity  route_avg_visibility  route_avg_pressure  distance  \\\n",
       "0               92.000000              6.000000         1019.666667   1412.20   \n",
       "1               65.666667              6.000000         1023.000000    371.86   \n",
       "4               93.500000              3.500000         1016.500000     69.24   \n",
       "5               58.000000              6.000000         1020.250000    559.02   \n",
       "6               67.857143              4.857143         1015.000000   1619.87   \n",
       "...                   ...                   ...                 ...       ...   \n",
       "10513           67.250000              5.750000         1007.750000    677.39   \n",
       "10515           88.333333              6.000000         1020.333333    454.49   \n",
       "10516           78.000000              6.000000         1021.333333    456.29   \n",
       "10517           77.666667              6.000000         1012.000000    478.08   \n",
       "10519           67.333333              6.000000         1013.666667    330.15   \n",
       "\n",
       "       average_hours  origin_temp  origin_wind_speed  ...  \\\n",
       "0              28.24         32.0                6.0  ...   \n",
       "1               7.44         57.0               11.0  ...   \n",
       "4               1.38         23.0                4.0  ...   \n",
       "5              11.18         21.0                8.0  ...   \n",
       "6              32.40         14.0               11.0  ...   \n",
       "...              ...          ...                ...  ...   \n",
       "10513          13.55         21.0               14.0  ...   \n",
       "10515           9.09         14.0                5.0  ...   \n",
       "10516           9.13         27.0               19.0  ...   \n",
       "10517           9.56         37.0                2.0  ...   \n",
       "10519           6.60         34.0                7.0  ...   \n",
       "\n",
       "       destination_description_Patchy rain possible  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "4                                               0.0   \n",
       "5                                               0.0   \n",
       "6                                               0.0   \n",
       "...                                             ...   \n",
       "10513                                           0.0   \n",
       "10515                                           0.0   \n",
       "10516                                           0.0   \n",
       "10517                                           0.0   \n",
       "10519                                           0.0   \n",
       "\n",
       "       destination_description_Patchy snow possible  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "4                                               0.0   \n",
       "5                                               0.0   \n",
       "6                                               0.0   \n",
       "...                                             ...   \n",
       "10513                                           0.0   \n",
       "10515                                           0.0   \n",
       "10516                                           0.0   \n",
       "10517                                           0.0   \n",
       "10519                                           0.0   \n",
       "\n",
       "       destination_description_Sunny  \\\n",
       "0                                0.0   \n",
       "1                                0.0   \n",
       "4                                1.0   \n",
       "5                                0.0   \n",
       "6                                1.0   \n",
       "...                              ...   \n",
       "10513                            0.0   \n",
       "10515                            1.0   \n",
       "10516                            0.0   \n",
       "10517                            0.0   \n",
       "10519                            1.0   \n",
       "\n",
       "       destination_description_Torrential rain shower  fuel_type_diesel  \\\n",
       "0                                                 0.0               1.0   \n",
       "1                                                 0.0               0.0   \n",
       "4                                                 0.0               0.0   \n",
       "5                                                 0.0               0.0   \n",
       "6                                                 0.0               1.0   \n",
       "...                                               ...               ...   \n",
       "10513                                             0.0               0.0   \n",
       "10515                                             0.0               0.0   \n",
       "10516                                             0.0               1.0   \n",
       "10517                                             0.0               1.0   \n",
       "10519                                             0.0               1.0   \n",
       "\n",
       "       fuel_type_gas  gender_female  gender_male  driving_style_conservative  \\\n",
       "0                0.0            0.0          1.0                         1.0   \n",
       "1                1.0            0.0          1.0                         1.0   \n",
       "4                1.0            0.0          1.0                         1.0   \n",
       "5                1.0            0.0          1.0                         1.0   \n",
       "6                0.0            0.0          1.0                         0.0   \n",
       "...              ...            ...          ...                         ...   \n",
       "10513            1.0            0.0          1.0                         0.0   \n",
       "10515            1.0            0.0          1.0                         0.0   \n",
       "10516            0.0            0.0          1.0                         1.0   \n",
       "10517            0.0            0.0          1.0                         1.0   \n",
       "10519            0.0            0.0          1.0                         0.0   \n",
       "\n",
       "       driving_style_proactive  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "4                          0.0  \n",
       "5                          0.0  \n",
       "6                          1.0  \n",
       "...                        ...  \n",
       "10513                      1.0  \n",
       "10515                      1.0  \n",
       "10516                      0.0  \n",
       "10517                      0.0  \n",
       "10519                      1.0  \n",
       "\n",
       "[7326 rows x 145 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  # or MinMaxScaler()\n",
    "X_train[cts_cols] = scaler.fit_transform(X_train[cts_cols])\n",
    "X_valid[cts_cols] = scaler.fit_transform(X_valid[cts_cols])\n",
    "X_test[cts_cols] = scaler.fit_transform(X_test[cts_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7326 entries, 0 to 10519\n",
      "Columns: 145 entries, route_avg_temp to driving_style_proactive\n",
      "dtypes: float64(142), int64(3)\n",
      "memory usage: 8.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 15:37:42,467 WARNING: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train['delay'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delay                                      1.000000\n",
       "is_midnight                                0.316212\n",
       "distance                                   0.218548\n",
       "average_hours                              0.218548\n",
       "accident                                   0.122483\n",
       "                                             ...   \n",
       "origin_description_Light snow             -0.039844\n",
       "origin_description_Patchy rain possible   -0.048887\n",
       "destination_description_Sunny             -0.081680\n",
       "avg_no_of_vehicles                        -0.114829\n",
       "destination_visibility                    -0.131476\n",
       "Name: delay, Length: 146, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = X_train.corr()\n",
    "\n",
    "# Extract correlation of all features with the target\n",
    "target_corr = corr_matrix['delay'].sort_values(ascending=False)\n",
    "\n",
    "# Print the correlation matrix\n",
    "# print(\"Correlation Matrix:\\n\", corr_matrix)\n",
    "\n",
    "# Print correlation with target column\n",
    "target_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Test accuracy: 0.6968043647700701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/18 15:16:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic_Regression: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "Accuracy: 0.7489539748953975, F1 Score: 0.7282572246829885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83      1293\n",
      "           1       0.69      0.41      0.51       619\n",
      "\n",
      "    accuracy                           0.75      1912\n",
      "   macro avg       0.73      0.66      0.67      1912\n",
      "weighted avg       0.74      0.75      0.73      1912\n",
      "\n",
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "Test accuracy: 0.6921278254091972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/18 15:21:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random_Forest: {'class_weight': None, 'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Accuracy: 0.7834728033472803, F1 Score: 0.7624070417911356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86      1293\n",
      "           1       0.80      0.44      0.57       619\n",
      "\n",
      "    accuracy                           0.78      1912\n",
      "   macro avg       0.79      0.69      0.71      1912\n",
      "weighted avg       0.79      0.78      0.76      1912\n",
      "\n",
      "Fitting 3 folds for each of 486 candidates, totalling 1458 fits\n",
      "2024-10-18 15:29:29,730 WARNING: UserWarning: [15:29:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "\n",
      "Test accuracy: 0.7201870615744349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/18 15:29:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost: {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500, 'scale_pos_weight': 1, 'subsample': 1}\n",
      "Accuracy: 0.7719665271966527, F1 Score: 0.7516241571771136\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85      1293\n",
      "           1       0.76      0.43      0.55       619\n",
      "\n",
      "    accuracy                           0.77      1912\n",
      "   macro avg       0.77      0.68      0.70      1912\n",
      "weighted avg       0.77      0.77      0.75      1912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import hsml\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import joblib  # For saving the model locally\n",
    "\n",
    "# Define X_train, X_valid, y_train, y_valid (use your existing datasets)\n",
    "X = X_train  # Assuming scaled features\n",
    "y = y_train\n",
    "\n",
    "# Split the data further for GridSearch if needed\n",
    "# X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"ML Models with Hyperparameter Tuning\")\n",
    "\n",
    "# Initialize Hopsworks connection\n",
    "connection = hsml.connection()  # Create a connection to Hopsworks\n",
    "mr = connection.get_model_registry()  # Get the Hopsworks model registry\n",
    "\n",
    "# Directory to save models temporarily\n",
    "model_dir = \"models/\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Define a function to train, log, and save models with MLflow and Hopsworks\n",
    "def train_and_evaluate_model(model, param_grid, model_name):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # GridSearchCV for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Get the best model from GridSearch\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_pred = best_model.predict(X_valid)\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        # Evaluate performance\n",
    "        acc = accuracy_score(y_valid, y_pred)\n",
    "        f1 = f1_score(y_valid, y_pred, average='weighted')\n",
    "\n",
    "        acc_test = accuracy_score(y_test, y_test_pred)\n",
    "        print(f\"Test accuracy: {acc_test}\")\n",
    "        # Log parameters, metrics, and model with MLflow\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metrics({\"accuracy\": acc, \"f1_score\": f1})\n",
    "        mlflow.sklearn.log_model(best_model, model_name)\n",
    "\n",
    "        # Save the model locally\n",
    "        # local_model_path = f\"{model_dir}{model_name}_model.pkl\"\n",
    "        # joblib.dump(best_model, local_model_path)\n",
    "\n",
    "        # # Create a model instance for Hopsworks model registry\n",
    "        # model_instance = mr.python.create_model(\n",
    "        #     name=model_name,\n",
    "        #     metrics={\"accuracy\": acc, \"f1_score\": f1},\n",
    "        #     description=f\"{model_name} with hyperparameter tuning\"\n",
    "        # )\n",
    "\n",
    "        # # Save the model to the Hopsworks Model Registry\n",
    "        # model_instance.save(local_model_path)\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Best Parameters for {model_name}: {grid_search.best_params_}\")\n",
    "        print(f\"Accuracy: {acc}, F1 Score: {f1}\")\n",
    "        print(classification_report(y_valid, y_pred))\n",
    "\n",
    "# Hyperparameter grids for each model\n",
    "logreg_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 200, 500]\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 10, 20, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced', None]  # Address imbalance\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'colsample_bytree': [0.3, 0.7, 1],\n",
    "    'subsample': [0.8, 1],\n",
    "    'scale_pos_weight': [1, 3, 5]  # For class imbalance\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "# Train and evaluate models with corrected model names\n",
    "train_and_evaluate_model(LogisticRegression(), logreg_params, \"Logistic_Regression\")\n",
    "train_and_evaluate_model(RandomForestClassifier(), rf_params, \"Random_Forest\")\n",
    "train_and_evaluate_model(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgb_params, \"XGBoost\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
